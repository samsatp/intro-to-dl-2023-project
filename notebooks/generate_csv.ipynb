{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import glob, os, lxml\n",
    "from utils import preprocess_text\n",
    "\n",
    "def data_extract(contents):\n",
    "    headlines = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    for xml in contents:\n",
    "        soup = BeautifulSoup(xml, features=\"xml\")\n",
    "\n",
    "        headlines.append(soup.headline.text)\n",
    "\n",
    "        text = ' '.join([\n",
    "            preprocess_text(t) \n",
    "            for t in soup.find('text').text.split('\\n')\n",
    "        ]).strip()\n",
    "        texts.append(text)\n",
    "\n",
    "        codes = soup.find_all(\"code\")\n",
    "        label = [code.attrs.get(\"code\") for code in codes]\n",
    "        labels.append(label)\n",
    "    return headlines, texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'test_data/reuters-test-data/reuters-test-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_csv(data_path, out_data = 'data.csv', get_labels = True, get_filenames = False):\n",
    "    filenames = []\n",
    "    contents = []\n",
    "    for file in os.listdir(data_path):\n",
    "\n",
    "        # Ignore special files\n",
    "        if file == 'codes.zip' or file == 'dtds.zip':\n",
    "            continue\n",
    "\n",
    "        file = os.path.join(data_path, file)\n",
    "\n",
    "        # Ignore other than zipfiles\n",
    "        if not zipfile.is_zipfile(file):\n",
    "            continue\n",
    "\n",
    "        # Open the zipfile\n",
    "        with zipfile.ZipFile(file, 'r') as zip_file: \n",
    "            for xml_file in zip_file.namelist():\n",
    "            # Read the contents of every file in the archive\n",
    "                with zip_file.open(xml_file) as f:\n",
    "                    filenames.append(f.name)\n",
    "                    contents.append(f.read())\n",
    "    headlines, texts, labels = data_extract(contents)\n",
    "    unique_labels = set([item for label in labels for item in label])\n",
    "    data = {'headline': headlines, 'text': texts}\n",
    "    if get_labels:\n",
    "        data['label'] = labels\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if get_filenames:\n",
    "        # Add filenames as indices\n",
    "        df.index = filenames\n",
    "\n",
    "    df.to_csv(out_data, sep = '|')\n",
    "\n",
    "\n",
    "generate_csv(DATA_PATH, \"test_data.csv\", get_labels = False, get_filenames = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
