{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/data_sample.csv\", sep=\"|\")\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test class methods:\n",
    "- build_vocab_from_data\n",
    "- build_vocab_from_pretrain_emb\n",
    "- build_with_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       " tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "         1, 0, 0, 1], dtype=torch.int16))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[\"headline\"].str.strip() + \" \" + df[\"text\"].str.strip()\n",
    "\n",
    "dataset = MultiLabelDataset.build_vocab_from_data(\n",
    "    data=data.values, \n",
    "    labels=df.label.values, \n",
    "    tokenizer=Tokenizer())\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     0,     0,    12,     0,     0,  4217,     0,     0,     0,\n",
       "             0,     0,     4,     0,     0,     0,     0,     0,  3069,  5749,\n",
       "             4,  1087,     0,   919, 24025,     0,  1246,     5,     0,     0,\n",
       "             0,    14,   970,     7,  1903,  2309,   588,     0,   134, 10393,\n",
       "             0,     4,     0,     0,     0,     0,     0,   177,  7124,     4,\n",
       "           408,     0,   997, 24025,     0,     0,     0,  3096,  1852,  2575,\n",
       "             6,  9068,     5,     0,     0,     0,     0,     4,     0,     0,\n",
       "             0,     0,     0,   233,  7124,     4,   207,     0,   997, 24025,\n",
       "             0,     0,     0,   195,     5,     0,     0,     0,     0,     0,\n",
       "             0]),\n",
       " tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "         1, 0, 0, 1], dtype=torch.int16))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MultiLabelDataset.build_vocab_from_pretrain_emb(\n",
    "    data=data.values, \n",
    "    labels=df.label.values, \n",
    "    tokenizer=Tokenizer(),\n",
    "    pretrained_name=\"glove.6B.50d\")\n",
    "\n",
    "dataset[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader, num_classes = get_dataloaders(\n",
    "    file=\"data/data_sample.csv\",\n",
    "    tokenizer=Tokenizer(),\n",
    "    vocab_from=\"glove.6B.50d\"\n",
    ")\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,  545, 3065,  ...,    0,    0,    0],\n",
      "        [   0,  896,  108,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   0,    0,   12,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,   12,  ...,    0,    0,    0]]), 'y': tensor([[0, 0, 0,  ..., 0, 1, 0],\n",
      "        [1, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int16), 'lengths': [6471, 754, 590, 534, 457, 304, 174, 173, 135, 133, 120, 117, 111, 109, 105, 102, 100, 91, 85, 74, 73, 69, 65]}\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[     0,    896,    157,  ...,  35115,  69312, 167123],\n",
      "        [     0,   1948,    384,  ...,      0,      0,      0],\n",
      "        [     0,   5428,      0,  ...,      0,      0,      0],\n",
      "        [     0,    211,      0,  ...,      0,      0,      0],\n",
      "        [     0,      0,      0,  ...,      0,      0,      0],\n",
      "        [     0,      0,     12,  ...,      0,      0,      0]]), 'y': tensor([[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0]],\n",
      "       dtype=torch.int16), 'lengths': [435, 353, 122, 120, 86, 60]}\n"
     ]
    }
   ],
   "source": [
    "for i in test_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader, num_classes = get_dataloaders(\n",
    "    file=\"data/data_sample.csv\",\n",
    "    vocab_from=\"bert\"\n",
    ")\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texts': tensor([[  101, 24529,  2063,  2758,  2097,  2025,  9190,  7987,  2063,  1011,\n",
      "          1060,  2006,  5227,  1012,  2044,  1037,  4121,  3872,  1997,  3119,\n",
      "          1999,  7987,  2063,  1060, 13246,  5183,  3303,  1996,  4361,  4518,\n",
      "          3863,   102],\n",
      "        [  101,  2470,  9499,  1011, 22326,  5821,  9725,  1012, 11605,  5253,\n",
      "         24665,  2368, 23510,  2056, 12941,  2848,  6287,  9725, 22326,  5821,\n",
      "         13058,  2000,  4965,  2013, 27598,  3038,  1996,  4518,  1055,  6689,\n",
      "          2018,   102],\n",
      "        [  101, 17235,  2850,  4160,  5494,  2087,  3161,  2015,  1011,  2258,\n",
      "          1015,  1012,  1996,  2206,  2020,  1996,  2087,  3161,  3314,  1999,\n",
      "         17235,  2850,  4160,  6202,  2006,  9857, 12367,  7646, 13058,  2484,\n",
      "          4261,   102],\n",
      "        [  101,  8915,  2072,  4297,  1053,  2549,  3463,  1012,  4951, 21020,\n",
      "          4483,  4297,  3479,  4082,  2592, 14477, 21041,  3064,  1999,  5190,\n",
      "          3272, 16565,  2566,  3745,  2093,  2706,  3092,  2285,  2861,  2727,\n",
      "          2786,   102],\n",
      "        [  101,  4714,  2710,  8930,  8704,  2000,  9611,  3902,  5654,  6547,\n",
      "          1012,  2096,  1996,  3902,  5654,  2751,  6704,  6634,  2015,  9387,\n",
      "          1998, 19119,  6202,  7588,  1037,  4714,  3010, 10552,  3813,  2003,\n",
      "          5168,   102],\n",
      "        [  101, 10465,  1024,  1057,  1012,  1055,  1012,  5971, 16565,  7505,\n",
      "         18136,  2063,  2951,  1012, 16565,  4474,  2005,  2258,  1015,  3024,\n",
      "          2011, 13658,  2015,  5211,  2470,  1996,  2206,  3316,  2988,  1996,\n",
      "          4602,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 1., 1., 1., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "for i in test_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
